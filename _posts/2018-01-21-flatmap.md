---
layout: post
category: Software, functional programming, scala
title: Flatmap
---

### Background

There is a reason why `flatMap` and its cousin `map` deserves a special place in the Scala folklore. It all starts from the [combinator pattern](https://wiki.haskell.org/Combinator_pattern) popularized by the functional programming paradigm, which according to its definition, is "a style of organizing libraries centered around the idea of combining things". Usually, there are a few ways to construct some primitive values of type `T` and a few `combinators` (functions) which can combine values of type `T` to build up more complex values of type `T`. Proponents of the combinator pattern argue that it promotes modularity and composibility of the program.

Many real world libraries are built using the combinator pattern, including the Scala [collection](https://www.scala-lang.org/api/2.12.3/scala/collection/index.html) and [parser combinator](http://www.scala-lang.org/api/2.12.3/scala-parser-combinators/scala/util/parsing/combinator/Parsers.html), [Dataset](https://spark.apache.org/docs/2.1.0/api/java/org/apache/spark/sql/Dataset.html) in Spark, [Queries](http://slick.lightbend.com/doc/3.2.1/queries.html) in Slick and many domain specific languages (DSLs).

If someone who wants to leverage the combinator pattern, the challenge is to come up with both the type `T` and a set of combinators for `T` to encapsulate whatever computation the author wants to express. If the computation happens to be sequential by nature, that is where `Monad` comes in handy.

There might be a lot of fuzz about `Monad`, but it is not much more than a type `T` with a few pre-defined `combinator` interfaces. At a high level, it allows us to 1) write a description of a computation and 2) have *a way* to apply a pure function to the result of the previous computation and transform it into the description of the next computation. With these two weapons at disposal, we can then take an initial description of the computation and sequentially transform it into the final description of the computation by applying a series of pure functions to it. As we can see here, the key of writing programs like this is how these pure functions get applied. `flatMap` defines exactly that.

In fact, sequential compuation are so common that `Monad` becomes the basis of many types that try to leverage the combinator pattern, to the point where many languages provide syntactic sugar to make the chaining of `flatMaps` less nested and more pleasant for eyes. In Scala, it is the keyword `for`.


### Meaning in different context

Let's look at `flatMap` in the context of a Scala `List`.

{% highlight scala linenos=table %}

scala> List(1, 2, 3).flatMap { i =>
     |   List(4, 5, 6).map { j =>
     |     (i, j)
     |   }
     | }
res0: List[(Int, Int)] = List((1,4), (1,5), (1,6), (2,4), (2,5), (2,6), (3,4), (3,5), (3,6))

{% endhighlight %}

If we change `flatMap` to `map` in the above example, the result would have been

{% highlight scala linenos=table %}

res0: List[List[(Int, Int)]] = List(List((1,4), (1,5), (1,6)), List((2,4), (2,5), (2,6)), List((3,4), (3,5), (3,6)))

{% endhighlight %}

The intuition here seems to be simple, `flatMap` maps first and then flattens out the resulting nested list. 

But if we think further, what kind of computation does `List[Int]` really encapsulate? One way of looking at it is that a `List[T]` represents something that has multiple but equally possible values. For example, `List(1, 2, 3)` could be considered as *one* value with 1/3 chance of being 1, 2 and 3 respectively. What `flatMap` does in the above example is that it combines elements in two list into a list of tuples with respect to the possibilities of each tuple being the potential value of it. e.g. `(1, 4)` has 1/9 of then chance of being the result of the final list because `1` and `4` both has 1/3 of the chance of being the value of the first and second list respectively.
